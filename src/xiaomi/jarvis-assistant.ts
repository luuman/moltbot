/**
 * Jarvis Voice Assistant
 * Local voice recognition + XiaoAI TTS
 *
 * Architecture:
 * - Microphone â†’ Voice Recognition (Whisper/Vosk) â†’ Wake Word Detection
 * - Command Processing â†’ Response Generation â†’ XiaoAI TTS
 */

import type { XiaomiClient } from "./client.js";

export interface JarvisConfig {
  wakeWord: string; // å”¤é†’è¯ï¼Œä¾‹å¦‚ "è´¾ç»´æ–¯"
  xiaomiClient: XiaomiClient;
  speakerDid: string; // å°çˆ±éŸ³ç®± DID
  // è¯­éŸ³è¯†åˆ«æœåŠ¡é…ç½®ï¼ˆå¾…å®ç°ï¼‰
  recognitionService?: {
    type: "whisper" | "vosk" | "local";
    apiKey?: string;
  };
}

export class JarvisAssistant {
  private config: JarvisConfig;
  private isListening: boolean = false;

  constructor(config: JarvisConfig) {
    this.config = config;
  }

  /**
   * å¯åŠ¨è´¾ç»´æ–¯åŠ©æ‰‹
   */
  async start(): Promise<void> {
    console.log(`ğŸ¤– è´¾ç»´æ–¯åŠ©æ‰‹å·²å¯åŠ¨ï¼Œå”¤é†’è¯: "${this.config.wakeWord}"`);
    this.isListening = true;

    // TODO: å®ç°è¯­éŸ³è¯†åˆ«å¾ªç¯
    // while (this.isListening) {
    //   const audio = await this.captureMicrophone();
    //   const text = await this.recognize(audio);
    //
    //   if (text.startsWith(this.config.wakeWord)) {
    //     await this.handleCommand(text);
    //   }
    // }
  }

  /**
   * åœæ­¢è´¾ç»´æ–¯åŠ©æ‰‹
   */
  stop(): void {
    this.isListening = false;
    console.log("ğŸ¤– è´¾ç»´æ–¯åŠ©æ‰‹å·²åœæ­¢");
  }

  /**
   * å¤„ç†è¯­éŸ³å‘½ä»¤
   */
  private async handleCommand(fullText: string): Promise<void> {
    // ç§»é™¤å”¤é†’è¯ï¼Œè·å–å®é™…å‘½ä»¤
    const command = fullText.replace(this.config.wakeWord, "").trim();

    console.log(`ğŸ“ æ”¶åˆ°å‘½ä»¤: ${command}`);

    // TODO: å®ç°å‘½ä»¤å¤„ç†é€»è¾‘
    // ä¾‹å¦‚ï¼š
    // - æŸ¥è¯¢å¤©æ°”
    // - æ§åˆ¶æ™ºèƒ½å®¶å±…
    // - é—®ç­”å¯¹è¯
    // - ç­‰ç­‰

    const response = await this.processCommand(command);

    // é€šè¿‡å°çˆ±æ’­æŠ¥å“åº”
    const xiaoai = this.config.xiaomiClient.createXiaoAISpeaker(this.config.speakerDid);
    await xiaoai.speak(response);
  }

  /**
   * å¤„ç†å‘½ä»¤å¹¶ç”Ÿæˆå“åº”
   */
  private async processCommand(command: string): Promise<string> {
    // ç®€å•çš„å‘½ä»¤å¤„ç†ç¤ºä¾‹
    if (command.includes("æ—¶é—´")) {
      const now = new Date();
      return `ç°åœ¨æ˜¯${now.getHours()}ç‚¹${now.getMinutes()}åˆ†`;
    }

    if (command.includes("å¤©æ°”")) {
      // TODO: è°ƒç”¨å¤©æ°” API
      return "ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦25åº¦";
    }

    // é»˜è®¤å“åº”
    return `æ”¶åˆ°å‘½ä»¤ï¼š${command}ã€‚æŠ±æ­‰ï¼Œæˆ‘è¿˜ä¸çŸ¥é“å¦‚ä½•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚`;
  }

  /**
   * æ•è·éº¦å…‹é£éŸ³é¢‘ï¼ˆå¾…å®ç°ï¼‰
   */
  private async captureMicrophone(): Promise<Buffer> {
    // TODO: å®ç°éº¦å…‹é£å½•éŸ³
    // å¯ä»¥ä½¿ç”¨ node-record-lpcm16 æˆ–å…¶ä»–åº“
    throw new Error("Microphone capture not implemented");
  }

  /**
   * è¯­éŸ³è¯†åˆ«ï¼ˆå¾…å®ç°ï¼‰
   */
  private async recognize(audio: Buffer): Promise<string> {
    // TODO: å®ç°è¯­éŸ³è¯†åˆ«
    // é€‰é¡¹1: ä½¿ç”¨ Whisper API
    // é€‰é¡¹2: ä½¿ç”¨ Vosk (ç¦»çº¿)
    // é€‰é¡¹3: ä½¿ç”¨å…¶ä»–è¯­éŸ³è¯†åˆ«æœåŠ¡
    throw new Error("Voice recognition not implemented");
  }
}

/**
 * ä½¿ç”¨ç¤ºä¾‹ï¼š
 *
 * const client = new XiaomiClient();
 * await client.init();
 *
 * const jarvis = new JarvisAssistant({
 *   wakeWord: "è´¾ç»´æ–¯",
 *   xiaomiClient: client,
 *   speakerDid: "289833424",
 * });
 *
 * await jarvis.start();
 */
